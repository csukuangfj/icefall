#!/usr/bin/env bash

# fix segmentation fault reported in https://github.com/k2-fsa/icefall/issues/674
export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python

set -exou pipefail

nj=15
stage=-1
stop_stage=11

. shared/parse_options.sh || exit 1

vocab_sizes=(
  4096
  # 2000
  # 1000
  # 500
)


# All files generated by this script are saved in "data".
# You can safely remove "data" and rerun this script to regenerate it.
mkdir -p data

if [ $stage -le 0 ] && [ $stop_stage -ge 0 ]; then
  if [ ! -f data/text ]; then
    python3 ./local/generate_text.py
  fi
fi

if [ $stage -le 1 ] && [ $stop_stage -ge 1 ]; then
  # data/text - the raw text
  # data/text_random - shuffled from data/text
  #
  # pushd data
  # shuf text > text_random
  # there are 191389921 lines in text_random
  #
  # split -l 19138992 ./text_random
  #
  # it generates xaa xab xac xad ... xaj
  #
  # popd

  for vocab_size in ${vocab_sizes[@]}; do
    lang_dir=data/lang_bbpe_${vocab_size}
    mkdir -p $lang_dir

    if [ ! -f $lang_dir/bbpe.model ]; then
      echo "It make take 40 minutes"
      ./local/train_bbpe_model.py \
        --lang-dir $lang_dir \
        --vocab-size $vocab_size \
        --transcript data/xaa
    fi

    if [ ! -f $lang_dir/tokens.txt ]; then
      python3 ./local/bpe_model_to_tokens.py $lang_dir/bbpe.model > $lang_dir/tokens.txt
    fi
  done
fi

if [ $stage -le 2 ] && [ $stop_stage -ge 2 ]; then
  if [ ! -f data/words.txt ]; then
    python3 ./local/prepare_words.py \
      --input-file ./data/text \
      --output-file ./data/words.txt
  fi
fi
